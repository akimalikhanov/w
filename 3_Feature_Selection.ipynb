{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a7896b",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd817286",
   "metadata": {},
   "source": [
    "In this short (compared to Feature Engineering one) notebook, I'll continue data preparation process. Here I'll try to \"filter down\" bloated dataset that we got at the end of previous notebook. Various techniques will be applied to select most useful for prediction features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff6af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyod.models.mad import MAD\n",
    "from scipy.stats import normaltest\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e7b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_lgbm_cv(features, target, col_tran, k=5):\n",
    "    metric_df=pd.DataFrame(columns=['Train AUC', 'Test AUC'])\n",
    "    feat_importances=[]\n",
    "    kfold=StratifiedKFold(k)\n",
    "    for f, (tr, te) in enumerate(kfold.split(features, y=target)):\n",
    "        X_train, y_train=features.iloc[tr, :], target.iloc[tr]\n",
    "        X_test, y_test=features.iloc[te, :], target.iloc[te]\n",
    "\n",
    "        X_train_tr=col_tran.fit_transform(X_train)\n",
    "        X_test_tr=col_tran.transform(X_test)\n",
    "        weight=np.count_nonzero(y_train==0)/np.count_nonzero(y_train==1)\n",
    "\n",
    "        params={'num_boost_round': 10000,\n",
    "                'objective': 'binary',\n",
    "                'scale_pos_weight': weight,\n",
    "                'metric': 'auc',\n",
    "                'learning_rate': 0.05,\n",
    "                'reg_alpha': 0.1,\n",
    "                'reg_lambda': 0.1,\n",
    "                'subsample': 0.8,\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 5,\n",
    "                'verbose': -1}\n",
    "\n",
    "        dtrain=lgb.Dataset(X_train_tr, label=y_train)\n",
    "        dval=lgb.Dataset(X_test_tr, label=y_test)\n",
    "\n",
    "        model=lgb.train(\n",
    "                params=params,\n",
    "                train_set=dtrain,\n",
    "                valid_sets=[dtrain, dval],\n",
    "                valid_names=['train', 'test'],\n",
    "                callbacks=[lgb.early_stopping(100, verbose=-1)],\n",
    "                verbose_eval=False)\n",
    "        \n",
    "        test_score, train_score=model.best_score['test']['auc'], model.best_score['train']['auc']\n",
    "        metric_df.loc[f]=[train_score, test_score]\n",
    "\n",
    "        feat_importances.append(model.feature_importance(importance_type='gain'))\n",
    "    \n",
    "    feat_importances=np.array(feat_importances).mean(axis=0)\n",
    "    feat_importances_df=pd.DataFrame({'feature': col_tran.get_feature_names_out(),\n",
    "                                        'importance': feat_importances})\n",
    "    metric_df.loc['Avg']=[metric_df['Train AUC'].mean(), metric_df['Test AUC'].mean()]\n",
    "    return metric_df, feat_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37e9da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_lgbm_cv_small(features, target, k=5):\n",
    "    metric_df=pd.DataFrame(columns=['Train AUC', 'Test AUC'])\n",
    "    feat_importances=[]\n",
    "    kfold=StratifiedKFold(k)\n",
    "    for f, (tr, te) in enumerate(kfold.split(features, y=target)):\n",
    "        X_train, y_train=features.iloc[tr, :], target.iloc[tr]\n",
    "        X_test, y_test=features.iloc[te, :], target.iloc[te]\n",
    "\n",
    "        weight=np.count_nonzero(y_train==0)/np.count_nonzero(y_train==1)\n",
    "\n",
    "        params={'num_boost_round': 10000,\n",
    "                'objective': 'binary',\n",
    "                'scale_pos_weight': weight,\n",
    "                'metric': 'auc',\n",
    "                'learning_rate': 0.05,\n",
    "                'reg_alpha': 0.1,\n",
    "                'reg_lambda': 0.1,\n",
    "                'subsample': 0.8,\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 5,\n",
    "                'verbose': -1}\n",
    "\n",
    "        dtrain=lgb.Dataset(X_train, label=y_train)\n",
    "        dval=lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "        model=lgb.train(\n",
    "                params=params,\n",
    "                train_set=dtrain,\n",
    "                valid_sets=[dtrain, dval],\n",
    "                valid_names=['train', 'test'],\n",
    "                callbacks=[lgb.early_stopping(100, verbose=-1)],\n",
    "                verbose_eval=False)\n",
    "        \n",
    "        test_score, train_score=model.best_score['test']['auc'], model.best_score['train']['auc']\n",
    "        metric_df.loc[f]=[train_score, test_score]\n",
    "\n",
    "        feat_importances.append(model.feature_importance(importance_type='gain'))\n",
    "    \n",
    "    feat_importances=np.array(feat_importances).mean(axis=0)\n",
    "    feat_importances_df=pd.DataFrame({'feature': features.columns,\n",
    "                                        'importance': feat_importances})\n",
    "    metric_df.loc['Avg']=[metric_df['Train AUC'].mean(), metric_df['Test AUC'].mean()]\n",
    "    return metric_df, feat_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d61120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def return_size(df):\n",
    "    \"\"\"Return size of dataframe in gigabytes\"\"\"\n",
    "    return round(sys.getsizeof(df) / 1e9, 2)\n",
    "\n",
    "def convert_types(df, print_info = False):\n",
    "    \n",
    "    original_memory = df.memory_usage().sum()\n",
    "    \n",
    "    # Iterate through each column\n",
    "    for c in df:\n",
    "        \n",
    "        # Convert ids and booleans to integers\n",
    "        if ('SK_ID' in c):\n",
    "            df[c] = df[c].fillna(0).astype(np.int32)\n",
    "            \n",
    "        # Convert objects to category\n",
    "        elif (df[c].dtype == 'object') and (df[c].nunique() < df.shape[0]):\n",
    "            df[c] = df[c].astype('category')\n",
    "        \n",
    "        # Booleans mapped to integers\n",
    "        elif list(df[c].unique()) == [1, 0]:\n",
    "            df[c] = df[c].astype(bool)\n",
    "        \n",
    "        # Float64 to float32\n",
    "        elif df[c].dtype == float:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "            \n",
    "        # Int64 to int32\n",
    "        elif df[c].dtype == int:\n",
    "            df[c] = df[c].astype(np.int32)\n",
    "        \n",
    "    new_memory = df.memory_usage().sum()\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'Original Memory Usage: {round(original_memory / 1e9, 2)} gb.')\n",
    "        print(f'New Memory Usage: {round(new_memory / 1e9, 2)} gb.')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "106d421d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 2.75 gb.\n",
      "New Memory Usage: 1.41 gb.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(307511, 1125)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('data/train_previous_raw.csv')\n",
    "train=convert_types(train, print_info=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73549b30",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d967ce0",
   "metadata": {},
   "source": [
    "One of the simplest methods of feature selection is to remove highly correlated features. Presence of this features can negatively affect model's ability to learn, generalize. Hence, we should remove them. One should select the treshold themselves, but it's usually 0.8-0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb603200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_mat=train.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5a511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper=corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(np.bool))\n",
    "# upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb786ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper.to_csv('data/corr_mat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee1aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper=pd.read_csv('data/corr_mat.csv').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb3f77",
   "metadata": {},
   "source": [
    "I chose 90% colinearity as a threshold, you can try other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8559b1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533 will be removed\n"
     ]
    }
   ],
   "source": [
    "to_drop=[column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "print(f'{len(to_drop)} will be removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9d1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bece9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 592)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f24ed6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttrain's auc: 0.840007\ttest's auc: 0.776108\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[317]\ttrain's auc: 0.856136\ttest's auc: 0.778147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttrain's auc: 0.844401\ttest's auc: 0.771501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttrain's auc: 0.847285\ttest's auc: 0.777417\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[434]\ttrain's auc: 0.874982\ttest's auc: 0.777167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.7761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8561</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.7715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8473</td>\n",
       "      <td>0.7774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.7772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg</th>\n",
       "      <td>0.8526</td>\n",
       "      <td>0.7761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Train AUC  Test AUC\n",
       "0       0.8400    0.7761\n",
       "1       0.8561    0.7781\n",
       "2       0.8444    0.7715\n",
       "3       0.8473    0.7774\n",
       "4       0.8750    0.7772\n",
       "Avg     0.8526    0.7761"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "X, y=train.drop('TARGET', axis=1), train['TARGET']\n",
    "cat_cols, num_cols=X.select_dtypes(include=['category', 'object']).columns, X.select_dtypes('number').columns\n",
    "\n",
    "res, importances=custom_lgbm_cv_small(X, y)\n",
    "res`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23a101ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttrain's auc: 0.847446\ttest's auc: 0.778629\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttrain's auc: 0.839317\ttest's auc: 0.778186\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[317]\ttrain's auc: 0.849113\ttest's auc: 0.773067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[315]\ttrain's auc: 0.848085\ttest's auc: 0.778294\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\ttrain's auc: 0.866888\ttest's auc: 0.775472\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.7786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.7782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8481</td>\n",
       "      <td>0.7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8669</td>\n",
       "      <td>0.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg</th>\n",
       "      <td>0.8502</td>\n",
       "      <td>0.7767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Train AUC  Test AUC\n",
       "0       0.8474    0.7786\n",
       "1       0.8393    0.7782\n",
       "2       0.8491    0.7731\n",
       "3       0.8481    0.7783\n",
       "4       0.8669    0.7755\n",
       "Avg     0.8502    0.7767"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y=train.drop('TARGET', axis=1), train['TARGET']\n",
    "cat_cols, num_cols=X.select_dtypes(include=['category', 'object']).columns, X.select_dtypes('number').columns\n",
    "\n",
    "ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "col_tr=ColumnTransformer([\n",
    "    ('cat', ohe, cat_cols),\n",
    "    ('num', 'passthrough', num_cols)\n",
    "])\n",
    "\n",
    "res, importances=custom_lgbm_cv(X, y, col_tr)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae700d4",
   "metadata": {},
   "source": [
    "## \"Empty\" features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3688d4a",
   "metadata": {},
   "source": [
    "Now I'll remove mostly empty features, i.e., features with 70-90% of NaNs. I'll re-use `miss_table` function from EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48869ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 539/592 columns with missing values\n",
      "Distribution by dtypes:\n",
      "float64    533\n",
      "object       6\n",
      "Name: Dtype, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>client_credit_AMT_PAYMENT_CURRENT_min_min</th>\n",
       "      <td>246451.0000</td>\n",
       "      <td>80.1438</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_CNT_DRAWINGS_OTHER_CURRENT_max_min</th>\n",
       "      <td>246371.0000</td>\n",
       "      <td>80.1178</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_AMT_DRAWINGS_POS_CURRENT_min_min</th>\n",
       "      <td>246371.0000</td>\n",
       "      <td>80.1178</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_CNT_DRAWINGS_OTHER_CURRENT_mean_min</th>\n",
       "      <td>246371.0000</td>\n",
       "      <td>80.1178</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_CNT_DRAWINGS_ATM_CURRENT_max_min</th>\n",
       "      <td>246371.0000</td>\n",
       "      <td>80.1178</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Count  Percent  \\\n",
       "client_credit_AMT_PAYMENT_CURRENT_min_min         246451.0000  80.1438   \n",
       "client_credit_CNT_DRAWINGS_OTHER_CURRENT_max_min  246371.0000  80.1178   \n",
       "client_credit_AMT_DRAWINGS_POS_CURRENT_min_min    246371.0000  80.1178   \n",
       "client_credit_CNT_DRAWINGS_OTHER_CURRENT_mean_min 246371.0000  80.1178   \n",
       "client_credit_CNT_DRAWINGS_ATM_CURRENT_max_min    246371.0000  80.1178   \n",
       "\n",
       "                                                     Dtype  \n",
       "client_credit_AMT_PAYMENT_CURRENT_min_min          float64  \n",
       "client_credit_CNT_DRAWINGS_OTHER_CURRENT_max_min   float64  \n",
       "client_credit_AMT_DRAWINGS_POS_CURRENT_min_min     float64  \n",
       "client_credit_CNT_DRAWINGS_OTHER_CURRENT_mean_min  float64  \n",
       "client_credit_CNT_DRAWINGS_ATM_CURRENT_max_min     float64  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def miss_table(data):\n",
    "    miss_table=data.isna().sum().to_frame(name='Count')\n",
    "    miss_table['Percent']=miss_table['Count']/len(data)*100\n",
    "    miss_table['Dtype']=data.dtypes[miss_table.index]\n",
    "    miss_table['Count']=miss_table['Count'].replace({0: np.nan})\n",
    "    miss_table=miss_table.dropna()\n",
    "    print(f\"There are {len(miss_table)}/{data.shape[1]} columns with missing values\")\n",
    "    print('Distribution by dtypes:')\n",
    "    print(miss_table['Dtype'].value_counts())\n",
    "    return miss_table.sort_values(by='Count', ascending=False)\n",
    "\n",
    "mt=miss_table(train)\n",
    "mt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffef8424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 features with 75% of NaNs will be removed\n"
     ]
    }
   ],
   "source": [
    "# to_drop=\n",
    "to_drop=mt.loc[mt['Percent']>75].index\n",
    "print(f'{len(to_drop)} features with 75% of NaNs will be removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "396ac92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 577)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train.drop(to_drop, axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e59d0",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd9d7d9",
   "metadata": {},
   "source": [
    "Feature importance that we get from tree-based models can be used for selecting features too. E.g., one can remove features with 0 importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d173923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a\n",
    "# https://www.signifytechnology.com/blog/2018/07/a-feature-selection-tool-for-machine-learning-in-python-by-william-koehrsen?source=google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79a29ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[291]\ttrain's auc: 0.843049\ttest's auc: 0.778366\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\ttrain's auc: 0.828317\ttest's auc: 0.778082\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\ttrain's auc: 0.84419\ttest's auc: 0.773263\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttrain's auc: 0.837489\ttest's auc: 0.778917\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[387]\ttrain's auc: 0.859407\ttest's auc: 0.776866\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8430</td>\n",
       "      <td>0.7784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8283</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.7733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8594</td>\n",
       "      <td>0.7769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg</th>\n",
       "      <td>0.8425</td>\n",
       "      <td>0.7771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Train AUC  Test AUC\n",
       "0       0.8430    0.7784\n",
       "1       0.8283    0.7781\n",
       "2       0.8442    0.7733\n",
       "3       0.8375    0.7789\n",
       "4       0.8594    0.7769\n",
       "Avg     0.8425    0.7771"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y=train.drop('TARGET', axis=1), train['TARGET']\n",
    "cat_cols, num_cols=X.select_dtypes(include=['category', 'object']).columns, X.select_dtypes('number').columns\n",
    "\n",
    "ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "col_tr=ColumnTransformer([\n",
    "    ('cat', ohe, cat_cols),\n",
    "    ('num', 'passthrough', num_cols)\n",
    "])\n",
    "\n",
    "res, importances=custom_lgbm_cv(X, y, col_tr)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9574372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_reserve=importances.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95273fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
