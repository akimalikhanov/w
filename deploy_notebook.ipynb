{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35b1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyod.models.mad import MAD\n",
    "from scipy.stats import normaltest\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_auc_score\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "from imports import *\n",
    "import gc\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "from utils import *\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ccfc1",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3480f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_size(df):\n",
    "    \"\"\"Return size of dataframe in gigabytes\"\"\"\n",
    "    return round(sys.getsizeof(df) / 1e9, 2)\n",
    "\n",
    "def convert_types(df, print_info = False):\n",
    "    \n",
    "    original_memory = df.memory_usage().sum()\n",
    "    \n",
    "    for c in df:\n",
    "        \n",
    "        if ('SK_ID' in c):\n",
    "            df[c] = df[c].fillna(0).astype(np.int32)\n",
    "        \n",
    "        elif list(df[c].unique()) == [1, 0]:\n",
    "            df[c] = df[c].astype(bool)\n",
    "        \n",
    "        elif df[c].dtype == np.float64:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "            \n",
    "        elif df[c].dtype == np.int64:\n",
    "            df[c] = df[c].astype(np.int32)\n",
    "        \n",
    "    new_memory = df.memory_usage().sum()\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'Original Memory Usage: {round(original_memory / 1e9, 2)} gb.')\n",
    "        print(f'New Memory Usage: {round(new_memory / 1e9, 2)} gb.')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def miss_table(data):\n",
    "    miss_table=data.isna().sum().to_frame(name='Count')\n",
    "    miss_table['Percent']=miss_table['Count']/len(data)*100\n",
    "    miss_table['Dtype']=data.dtypes[miss_table.index]\n",
    "    miss_table['Count']=miss_table['Count'].replace({0: np.nan})\n",
    "    miss_table=miss_table.dropna()\n",
    "    print(f\"There are {len(miss_table)}/{data.shape[1]} columns with missing values\")\n",
    "    print('Distribution by dtypes:')\n",
    "    print(miss_table['Dtype'].value_counts())\n",
    "    return miss_table.sort_values(by='Count', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "def generate_domain_features(df):\n",
    "    # CREDIT related \n",
    "    bins=[18, 35, 40, 50, 60, 70, 120]\n",
    "    labels=['18-29', '30-39', '40-49', '50-59', '60-69', '70+']\n",
    "    df['NEW_AGE_GROUP']=pd.cut(df['DAYS_BIRTH']/-365, bins=bins, labels=labels, right=False).astype('object')\n",
    "\n",
    "    cred_by_contract=df.groupby('NAME_CONTRACT_TYPE')['AMT_CREDIT'].mean() \n",
    "    cred_by_housing_type=df.groupby('NAME_HOUSING_TYPE')['AMT_CREDIT'].mean() \n",
    "    cred_by_org_type=df.groupby('ORGANIZATION_TYPE')['AMT_CREDIT'].mean() \n",
    "    cred_by_education_type=df.groupby('NAME_EDUCATION_TYPE')['AMT_CREDIT'].mean() \n",
    "    cred_by_gender=df.groupby('CODE_GENDER')['AMT_CREDIT'].mean() \n",
    "    cred_by_family_status=df.groupby('NAME_FAMILY_STATUS')['AMT_CREDIT'].mean()\n",
    "    cred_by_age_group=df.groupby('NEW_AGE_GROUP')['AMT_CREDIT'].mean()\n",
    "\n",
    "    df['NEW_AMT_CREDIT_TO_AMT_INCOME']=df['AMT_CREDIT']/df['AMT_INCOME_TOTAL'] \n",
    "    df['NEW_AMT_CREDIT_TO_AMT_ANNUITY']=df['AMT_CREDIT']/df['AMT_ANNUITY']\n",
    "    df['NEW_AMT_CREDIT_TO_AMT_GOODS_PRICE']=df['AMT_CREDIT']/df['AMT_GOODS_PRICE']\n",
    "    df['NEW_AMT_CREDIT_TO_MEAN_AMT_CREDIT_BY_CONTRACT_TYPE']=df['AMT_CREDIT']/(df['NAME_CONTRACT_TYPE'].map(cred_by_contract))\n",
    "    df['NEW_AMT_CREDIT_TO_MEAN_AMT_CREDIT_BY_HOUSING_TYPE']=df['AMT_CREDIT']/(df['NAME_HOUSING_TYPE'].map(cred_by_housing_type))\n",
    "    df['NEW_AMT_CREDIT_TO_MEAN_AMT_CREDIT_BY_ORGANIZATION_TYPE']=df['AMT_CREDIT']/(df['ORGANIZATION_TYPE'].map(cred_by_org_type))\n",
    "    df['NEW_AMT_CREDIT_TO_MEAN_AMT_CREDIT_BY_EDUCATION_TYPE']=df['AMT_CREDIT']/(df['NAME_EDUCATION_TYPE'].map(cred_by_education_type))\n",
    "    df['NEW_AMT_CREDIT_TO_MEAN_AMT_CREDIT_BY_GENDER']=df['AMT_CREDIT']/(df['CODE_GENDER'].map(cred_by_gender))\n",
    "    df['NEW_AMT_CREDIT_TO_MEAN_AMT_CREDIT_BY_FAMILY_STATUS']=df['AMT_CREDIT']/(df['NAME_FAMILY_STATUS'].map(cred_by_family_status))\n",
    "    df['NEW_AMT_CREDIT_TO_MEAN_AMT_INCOME_BY_AGE_GROUP']=df['AMT_CREDIT']/df['NEW_AGE_GROUP'].map(cred_by_age_group)\n",
    "\n",
    "\n",
    "    # INCOME related\n",
    "    inc_by_contract=df.groupby('NAME_CONTRACT_TYPE')['AMT_INCOME_TOTAL'].mean() \n",
    "    inc_by_housing_type=df.groupby('NAME_HOUSING_TYPE')['AMT_INCOME_TOTAL'].mean() \n",
    "    inc_by_org_type=df.groupby('ORGANIZATION_TYPE')['AMT_INCOME_TOTAL'].mean() \n",
    "    inc_by_education_type=df.groupby('NAME_EDUCATION_TYPE')['AMT_INCOME_TOTAL'].mean() \n",
    "    inc_by_gender=df.groupby('CODE_GENDER')['AMT_INCOME_TOTAL'].mean()\n",
    "    inc_by_family_status=df.groupby('NAME_FAMILY_STATUS')['AMT_INCOME_TOTAL'].mean()\n",
    "    inc_by_age_group=df.groupby('NEW_AGE_GROUP')['AMT_INCOME_TOTAL'].mean()\n",
    "\n",
    "    df['NEW_AMT_INCOME_BY_AGE_GROUP']=df['AMT_INCOME_TOTAL']/df['NEW_AGE_GROUP'].map(inc_by_age_group)\n",
    "    df['NEW_AMT_INCOME_BY_CNT_CHILD']=df['AMT_INCOME_TOTAL']/(1+df['CNT_CHILDREN'])\n",
    "    df['NEW_AMT_INCOME_BY_CNT_FAM_MEMBERS']=df['AMT_INCOME_TOTAL']/df['CNT_FAM_MEMBERS']\n",
    "    df['NEW_AMT_INCOME_BY_AGE']=df['AMT_INCOME_TOTAL']/(df['DAYS_BIRTH']/-365)\n",
    "    df['NEW_AMT_INCOME_TO_MEAN_AMT_CREDIT_BY_CONTRACT_TYPE']=df['AMT_INCOME_TOTAL']/(df['NAME_CONTRACT_TYPE'].map(inc_by_contract))\n",
    "    df['NEW_AMT_INCOME_TO_MEAN_AMT_CREDIT_BY_HOUSING_TYPE']=df['AMT_INCOME_TOTAL']/(df['NAME_HOUSING_TYPE'].map(inc_by_housing_type))\n",
    "    df['NEW_AMT_INCOME_TO_MEAN_AMT_CREDIT_BY_ORGANIZATION_TYPE']=df['AMT_INCOME_TOTAL']/(df['ORGANIZATION_TYPE'].map(inc_by_org_type))\n",
    "    df['NEW_AMT_INCOME_TO_MEAN_AMT_CREDIT_BY_EDUCATION_TYPE']=df['AMT_INCOME_TOTAL']/(df['NAME_EDUCATION_TYPE'].map(inc_by_education_type))\n",
    "    df['NEW_AMT_INCOME_TO_MEAN_AMT_CREDIT_BY_GENDER']=df['AMT_INCOME_TOTAL']/(df['CODE_GENDER'].map(inc_by_gender))\n",
    "    df['NEW_AMT_CREDIT_TO_MEAN_AMT_CREDIT_BY_FAMILY_STATUS']=df['AMT_CREDIT']/(df['NAME_FAMILY_STATUS'].map(inc_by_family_status))\n",
    "    df['NEW_AMT_INCOME_TO_MEAN_AMT_INCOME_BY_AGE_GROUP']=df['AMT_INCOME_TOTAL']/df['NEW_AGE_GROUP'].map(inc_by_age_group)\n",
    "\n",
    "\n",
    "    # FLAG related\n",
    "    # doc_flags--20 columns about documents\n",
    "    # contact_flags--6 flags about contact info of client (FLAG_MOBIL, FLAG_EMAIL, etc)\n",
    "    # address_flags--6 flags about address info of client (REG_REGION_NOT_LIVE_REGION, REG_REGION_NOT_WORK_REGION, etc)\n",
    "    doc_flags=[i for i in df.columns if 'FLAG_DOCUMENT' in i]\n",
    "    contact_flags=[i for i in df.columns if ('FLAG' in i) and (i not in doc_flags) and (i not in ('FLAG_OWN_CAR', 'FLAG_OWN_REALTY'))]\n",
    "    address_flags=[i for i in df.columns if 'NOT' in i]\n",
    "    flag_map={'Y':1, 'N':0}\n",
    "\n",
    "    df['NEW_DOC_FLAG_MEAN']=df[doc_flags].mean(axis=1)\n",
    "    df['NEW_DOC_FLAG_SUM']=df[doc_flags].sum(axis=1)\n",
    "    df['NEW_CONTACT_FLAG_MEAN']=df[contact_flags].mean(axis=1)\n",
    "    df['NEW_CONTACT_FLAG_SUM']=df[contact_flags].sum(axis=1)\n",
    "    df['NEW_ADDRESS_FLAG_MEAN']=df[address_flags].mean(axis=1)\n",
    "    df['NEW_ADDRESS_FLAG_SUM']=df[address_flags].sum(axis=1)\n",
    "    df['NEW_OWN_CAR_REALTY_COMBINATION']=0.75*df['FLAG_OWN_REALTY'].map(flag_map)+0.25*df['FLAG_OWN_CAR'].map(flag_map)\n",
    "\n",
    "\n",
    "    # AGE related\n",
    "    age_by_housing_type=df.groupby('NAME_HOUSING_TYPE')['DAYS_BIRTH'].mean()\n",
    "    age_by_own_realty=df.groupby('FLAG_OWN_REALTY')['DAYS_BIRTH'].mean()\n",
    "    age_by_own_car=df.groupby('FLAG_OWN_CAR')['DAYS_BIRTH'].mean()\n",
    "\n",
    "    df['NEW_AGE_TO_MEAN_AGE_BY_FLAG_OWN_REALTY']=df['DAYS_BIRTH']/(df['FLAG_OWN_REALTY'].map(age_by_own_realty))\n",
    "    df['NEW_AGE_TO_MEAN_AGE_BY_FLAG_OWN_CAR']=df['DAYS_BIRTH']/(df['FLAG_OWN_CAR'].map(age_by_own_car))\n",
    "    df['NEW_AGE_TO_MEAN_AGE_BY_HOUSING_TYPE']=df['DAYS_BIRTH']/(df['NAME_HOUSING_TYPE'].map(age_by_housing_type))\n",
    "    df[\"NEW_DAYS_EMPLOYED_TO_DAYS_BIRTH\"]=df['DAYS_EMPLOYED']/df['DAYS_BIRTH']\n",
    "    df[\"NEW_DAYS_REGISTRATION_TO_DAYS_BIRTH\"]=df['DAYS_REGISTRATION']/df['DAYS_BIRTH']\n",
    "\n",
    "\n",
    "    # Other\n",
    "    df['NEW_OWN_CAR_AGE_TO_DAYS_BIRTH']=df['OWN_CAR_AGE']/df['DAYS_BIRTH']\n",
    "    df['NEW_OWN_CAR_AGE_TO_DAYS_EMPLOYED']=df['OWN_CAR_AGE']/df['DAYS_EMPLOYED']\n",
    "    df['NEW_DAYS_LAST_PHONE_CHANGE_TO_DAYS_BIRTH']=df['DAYS_LAST_PHONE_CHANGE']/df['DAYS_BIRTH']\n",
    "    df['NEW_DAYS_LAST_PHONE_CHANGE_TO_DAYS_EMPLOYED']=df['DAYS_LAST_PHONE_CHANGE']/df['DAYS_EMPLOYED']\n",
    "    df['NEW_CNT_CHILD_TO_CNT_FAM_MEMBERS']=df['CNT_CHILDREN']/df['CNT_FAM_MEMBERS']\n",
    "    df['NEW_EXT_SOURCES_MEAN']=df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    df['NEW_EXT_SOURCES_STD']=df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "    df['NEW_DAYS_CHANGE_MEAN']=df[['DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE', 'DAYS_REGISTRATION']].mean(axis=1)\n",
    "    df['NEW_REGION_RATING_CLIENT_MEAN']=df[['REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY']].mean(axis=1)\n",
    "    df['NEW_30_CNT_SOCIAL_CIRCLE_MEAN']=df[['OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE']].mean(axis=1)\n",
    "    df['NEW_60_CNT_SOCIAL_CIRCLE_MEAN']=df[['OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']].mean(axis=1)\n",
    "    \n",
    "    print(f'After adding features: {df.shape}')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def numeric_agg(df, group_col, df_name):\n",
    "    num_df=df.select_dtypes('number')\n",
    "    if num_df.shape[1]!=0:\n",
    "        for c in num_df.columns:\n",
    "            if 'ID' in c and c!=group_col:\n",
    "                num_df=num_df.drop(c, axis=1)\n",
    "        df_agg=num_df.groupby(group_col).agg(['count', 'mean', 'max', 'min', 'sum'])\n",
    "\n",
    "        new_cols=[]\n",
    "        for l1 in df_agg.columns.levels[0]:\n",
    "            if l1!=group_col:\n",
    "                for l2 in df_agg.columns.levels[1]: # for stat in agg.columns.levels[1][:-1]\n",
    "                    new_cols.append(f'{df_name}_{l1}_{l2}')\n",
    "        df_agg.columns=new_cols\n",
    "        # Remove duplicate columns by values\n",
    "        _, idx = np.unique(df_agg, axis = 1, return_index = True)\n",
    "        df_agg = df_agg.iloc[:, idx]\n",
    "        print(f'Dataset:{df_name}\\n\\tBefore: {num_df.shape[1]} numeric cols\\n\\tAfter: {df_agg.shape[1]}')\n",
    "        return df_agg\n",
    "    else:\n",
    "        print('No numeric columns in dataframe')\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def categ_agg(df, group_col, df_name, enc, enc_mode='train'):\n",
    "    cat_df=df.select_dtypes(include=['object'])\n",
    "    if cat_df.shape[1]!=0:\n",
    "        if enc_mode=='train':\n",
    "            cat_df_ohe=enc.fit_transform(cat_df)\n",
    "        elif enc_mode=='test': \n",
    "            cat_df_ohe=enc.transform(cat_df)\n",
    "        cat_df_ohe=pd.DataFrame(cat_df_ohe, columns=enc.get_feature_names_out())\n",
    "        cat_df_ohe[group_col]=df[group_col]\n",
    "        df_agg=cat_df_ohe.groupby(group_col).agg(['sum', 'mean'])\n",
    "\n",
    "        new_cols=[]\n",
    "        for l1 in df_agg.columns.levels[0]:\n",
    "            for l2 in ['count', 'count_norm']: # more suitable aliases for sum and mean\n",
    "                new_cols.append(f'{df_name}_{l1}_{l2}')\n",
    "        df_agg.columns=new_cols\n",
    "        # Remove duplicate columns by values\n",
    "        _, idx = np.unique(df_agg, axis = 1, return_index = True)\n",
    "        df_agg = df_agg.iloc[:, idx]\n",
    "        print(f'Dataset:{df_name}\\n\\tBefore: {cat_df.shape[1]} categorical cols\\n\\tAfter: {df_agg.shape[1]}')\n",
    "        return df_agg\n",
    "    else:\n",
    "        print('No categorical columns in dataframe')\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def agg_combine(df, group_vars, df_names, enc, enc_mode='train', agg_level=1):\n",
    "    if agg_level==2:\n",
    "        df_cat_agg=categ_agg(df, group_vars[1], df_names[1], enc, enc_mode)\n",
    "        df_num_agg=numeric_agg(df, group_vars[1], df_names[1])\n",
    "        df_full_l2=df_cat_agg.merge(df_num_agg, on=group_vars[1], how='outer')\n",
    "        df_full_l2=df[group_vars].merge(df_full_l2, on=group_vars[1], how='right')\n",
    "        df_full=numeric_agg(df_full_l2, group_vars[0], df_names[0])\n",
    "        gc.enable()\n",
    "        del df_full_l2\n",
    "        gc.collect()\n",
    "    elif agg_level==1:\n",
    "        df_cat_agg=categ_agg(df, group_vars[0], df_names[0], enc, enc_mode)\n",
    "        df_num_agg=numeric_agg(df, group_vars[0], df_names[0])\n",
    "        df_full=df_cat_agg.merge(df_num_agg, on=group_vars[0], how='outer')\n",
    "    else:\n",
    "        return 'Select aggregation level 1 or 2'\n",
    "    gc.enable()\n",
    "    del df_cat_agg, df_num_agg\n",
    "    gc.collect()\n",
    "    return df_full\n",
    "\n",
    "\n",
    "\n",
    "def application_data(path):\n",
    "    df=pd.read_csv(path)\n",
    "    print(f'Application data shape: {df.shape}')\n",
    "    df['DAYS_EMPLOYED']=df['DAYS_EMPLOYED'].replace(365243, np.nan)\n",
    "    df=generate_domain_features(df)\n",
    "    return convert_types(df)\n",
    "\n",
    "\n",
    "\n",
    "def bureau_and_bb(bur_path, bb_path, enc_mode='test', bur_ohe=None, bb_ohe=None):\n",
    "    bur=convert_types(pd.read_csv(bur_path))\n",
    "    bb=convert_types(pd.read_csv(bb_path))\n",
    "    print(f'Bureau shape: {bur.shape}')\n",
    "    print(f'Bureau balance shape: {bb.shape}')\n",
    "    if not bb_ohe:\n",
    "        bb_ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        enc_mode='train'\n",
    "    bb_numeric_agg_df=numeric_agg(bb, 'SK_ID_BUREAU', 'bureau_balance')\n",
    "    bb_categ_agg_df=categ_agg(bb, 'SK_ID_BUREAU', 'bureau_balance', bb_ohe, enc_mode)\n",
    "    bb_full=bb_numeric_agg_df.merge(bb_categ_agg_df, on='SK_ID_BUREAU', how='outer')\n",
    "    bb_by_credit=bur[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bb_full, on='SK_ID_BUREAU', how='left') \n",
    "    bb=numeric_agg(bb_by_credit, 'SK_ID_CURR', 'loan') \n",
    "    if not bur_ohe:\n",
    "        bur_ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        enc_mode='train'\n",
    "    bur=agg_combine(bur, ['SK_ID_CURR'], ['bureau'], bur_ohe, enc_mode)\n",
    "    del bb_numeric_agg_df, bb_categ_agg_df, bb_full, bb_by_credit; gc.collect()\n",
    "    return bur, bb, bur_ohe, bb_ohe\n",
    "\n",
    "\n",
    "\n",
    "def previous(prev_path, enc_mode='test', prev_ohe=None):\n",
    "    prev=convert_types(pd.read_csv(prev_path))\n",
    "    print(f'Previous shape: {prev.shape}')\n",
    "    for c in ['DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION']:\n",
    "        prev[c]=prev[c].replace(365243, np.nan)\n",
    "    if not prev_ohe:\n",
    "        prev_ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        enc_mode='train'\n",
    "    prev=agg_combine(prev, ['SK_ID_CURR'], ['previous'], prev_ohe, enc_mode)\n",
    "    return prev, prev_ohe\n",
    "\n",
    "\n",
    "\n",
    "def pos_cash(cash_path, enc_mode='test', cash_ohe=None):\n",
    "    cash=convert_types(pd.read_csv(cash_path))\n",
    "    print(f'Cash shape: {cash.shape}')\n",
    "    if not cash_ohe:\n",
    "        cash_ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        enc_mode='train'\n",
    "    cash=agg_combine(cash, ['SK_ID_CURR', 'SK_ID_PREV'], ['loan', 'cash'], cash_ohe, enc_mode, agg_level=2)\n",
    "    return cash, cash_ohe\n",
    "\n",
    "\n",
    "\n",
    "def installments(inst_path):\n",
    "    inst=convert_types(pd.read_csv(inst_path))\n",
    "    print(f'Installments shape: {inst.shape}')\n",
    "    inst_agg_by_prev=numeric_agg(inst, 'SK_ID_PREV', 'inst')\n",
    "    inst_agg_by_prev=inst[['SK_ID_PREV', 'SK_ID_CURR']].merge(inst_agg_by_prev, on='SK_ID_PREV', how='right')\n",
    "    inst=numeric_agg(inst_agg_by_prev, 'SK_ID_CURR', 'loan')\n",
    "    del inst_agg_by_prev; gc.collect()\n",
    "    return inst\n",
    "\n",
    "\n",
    "\n",
    "def card_balance(card_path, enc_mode='test', card_ohe=None):\n",
    "    card_balance=convert_types(pd.read_csv(card_path))\n",
    "    print(f'Card Balance shape: {card_balance.shape}')\n",
    "    if not card_ohe:\n",
    "        card_ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        enc_mode='train'\n",
    "    card_balance=agg_combine(card_balance, ['SK_ID_CURR', 'SK_ID_PREV'], ['loan', 'card'], card_ohe, enc_mode, agg_level=2)\n",
    "    return card_balance, card_ohe\n",
    "\n",
    "\n",
    "\n",
    "def full_df(path_dict, mode='train'):\n",
    "    if mode=='train':\n",
    "        ohe_dict={}\n",
    "        app=application_data(path_dict['application_train'])\n",
    "        bur, bb, bur_ohe, bb_ohe=bureau_and_bb(path_dict['bur'], path_dict['bb'])\n",
    "        app=app.merge(bur, on='SK_ID_CURR', how='left')\n",
    "        ohe_dict['Bureau_OHE']=bur_ohe\n",
    "        ohe_dict['BB_OHE']= bb_ohe\n",
    "        del bur, bur_ohe; gc.collect()\n",
    "        app=app.merge(bb, on='SK_ID_CURR', how='left')\n",
    "        del bb, bb_ohe; gc.collect()\n",
    "        \n",
    "        prev, prev_ohe=previous(path_dict['previous'])\n",
    "        app=app.merge(prev, on='SK_ID_CURR', how='left')\n",
    "        ohe_dict['Prev_OHE']= prev_ohe\n",
    "        del prev, prev_ohe; gc.collect()\n",
    "        \n",
    "        cash, cash_ohe=pos_cash(path_dict['cash'])\n",
    "        app=app.merge(cash, on='SK_ID_CURR', how='left')\n",
    "        ohe_dict['Cash_OHE']= cash_ohe\n",
    "        del cash, cash_ohe; gc.collect()\n",
    "        \n",
    "        inst=installments(path_dict['installments'])\n",
    "        app=app.merge(inst, on='SK_ID_CURR', how='left')\n",
    "        del inst; gc.collect()\n",
    "        \n",
    "        card_b, card_b_ohe=card_balance(path_dict['card_balance'])\n",
    "        app=app.merge(card_b, on='SK_ID_CURR', how='left')\n",
    "        ohe_dict['Card_OHE']=card_b_ohe\n",
    "        del card_b, card_b_ohe; gc.collect()\n",
    "       \n",
    "        with open(path_dict['ohe_dict'], 'wb') as f:\n",
    "            pickle.dump(ohe_dict, f)\n",
    "        \n",
    "    elif mode=='test':\n",
    "        with open(path_dict['ohe_dict'], 'rb') as f:\n",
    "            ohe_dict=pickle.load(f)\n",
    "        app=application_data(path_dict['application_test'])\n",
    "        bur, bb, _, _=bureau_and_bb(path_dict['bur'], \n",
    "                                    path_dict['bb'], \n",
    "                                    bur_ohe=ohe_dict['Bureau_OHE'], \n",
    "                                    bb_ohe=ohe_dict['BB_OHE'])\n",
    "        app=app.merge(bur, on='SK_ID_CURR', how='left')\n",
    "        del bur; gc.collect()\n",
    "        app=app.merge(bb, on='SK_ID_CURR', how='left')\n",
    "        del bb; gc.collect()\n",
    "        \n",
    "        prev, _=previous(path_dict['previous'], prev_ohe=ohe_dict['Prev_OHE'])\n",
    "        app=app.merge(prev, on='SK_ID_CURR', how='left')\n",
    "        del prev; gc.collect()\n",
    "        \n",
    "        cash, _=pos_cash(path_dict['cash'], cash_ohe=ohe_dict['Cash_OHE'])\n",
    "        app=app.merge(cash, on='SK_ID_CURR', how='left')\n",
    "        del cash; gc.collect()\n",
    "        \n",
    "        inst=installments(path_dict['installments'])\n",
    "        app=app.merge(inst, on='SK_ID_CURR', how='left')\n",
    "        del inst; gc.collect()\n",
    "        \n",
    "        card_b, _=card_balance(path_dict['card_balance'], card_ohe=ohe_dict['Card_OHE'])\n",
    "        app=app.merge(card_b, on='SK_ID_CURR', how='left')\n",
    "        del card_b; gc.collect()\n",
    "    else:\n",
    "        raise Exception(\"Specify mode (train of test) and OHE dict bool\")\n",
    "\n",
    "    app=app.rename(columns=lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return convert_types(app)\n",
    "\n",
    "\n",
    "\n",
    "def correlation_filter(df, thresh, corr_path, mode='train'):\n",
    "    if mode=='train':\n",
    "        corr_mat=df.drop(['SK_ID_CURR', 'TARGET'], axis=1).corr().abs()\n",
    "        upper=corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(np.bool))\n",
    "        upper.to_csv(corr_path, index=False)\n",
    "    elif mode=='test':\n",
    "        upper=pd.read_csv(corr_path)\n",
    "    to_drop=[column for column in upper.columns if any(upper[column]>thresh)]\n",
    "    print(f'Correlation: {len(to_drop)} will be removed')\n",
    "    return df.drop(to_drop, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def missing_filter(df, thresh, col_path, mode='train'):\n",
    "    if mode=='train':\n",
    "        mt=miss_table(df)\n",
    "        to_drop=mt.loc[mt['Percent']>thresh].index\n",
    "        with open(col_path, 'wb') as f:\n",
    "            pickle.dump(to_drop, f)\n",
    "    elif mode=='test':\n",
    "        with open(col_path, 'rb') as f:\n",
    "            to_drop=pickle.load(f)\n",
    "    else:\n",
    "        raise Exception(\"Specify mode (train of test) and path\")\n",
    "    print(f'{len(to_drop)} features with {thresh}% of NaNs will be removed')\n",
    "    return df.drop(to_drop, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def zero_var_filter(df, col_path, mode='train'):\n",
    "    if mode=='train':\n",
    "        scaler=MinMaxScaler()\n",
    "        numeric_data=df.drop('SK_ID_CURR', axis=1).select_dtypes('number').reset_index(drop=True)\n",
    "        numeric_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        for i in numeric_data.columns:\n",
    "            numeric_data[i].fillna(value=numeric_data[i].mean(), inplace=True) #replace NaN with mean of dimension\n",
    "            numeric_data[i]=scaler.fit_transform(numeric_data[i].values.reshape(-1,1)) \n",
    "        vars_df=numeric_data.var()\n",
    "        to_drop=vars_df[vars_df==0].index\n",
    "        with open(col_path, 'wb') as f:\n",
    "            pickle.dump(to_drop, f)\n",
    "    \n",
    "    elif mode=='test':\n",
    "        with open(col_path, 'rb') as f:\n",
    "            to_drop=pickle.load(f)\n",
    "    else:\n",
    "        raise Exception(\"Specify mode (train of test) and path\")\n",
    "    print(f'{len(to_drop)} features with zero variance will be removed')\n",
    "    return df.drop(to_drop, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def feat_imp_cv(df, feat_imp_path, k=5, params=None, mode='train'):\n",
    "    if mode=='train':\n",
    "        data=df.copy()\n",
    "        for c in data:\n",
    "            if (data[c].dtype=='object') and (data[c].nunique()<data.shape[0]):\n",
    "                data[c]=data[c].astype('category')\n",
    "        X, y=data.drop(['SK_ID_CURR', 'TARGET'], axis=1), data['TARGET']\n",
    "        feat_importances_gain, feat_importances_split=[], []\n",
    "        cols=list(X.columns)\n",
    "        cat_feats=list(X.select_dtypes(['category']).columns)\n",
    "        kfold=StratifiedKFold(k)\n",
    "        for f, (tr, te) in enumerate(kfold.split(X, y=y)):\n",
    "            X_train, y_train=X.iloc[tr, :], y.iloc[tr]\n",
    "            X_test, y_test=X.iloc[te, :], y.iloc[te]\n",
    "            weight=np.count_nonzero(y_train==0)/np.count_nonzero(y_train==1)\n",
    "            params['scale_pos_weight']=weight\n",
    "            dtrain=lgb.Dataset(X_train, label=y_train, params={'verbose': -1})\n",
    "            dval=lgb.Dataset(X_test, label=y_test, params={'verbose': -1})\n",
    "            model=lgb.train(\n",
    "                            params=params,\n",
    "                            train_set=dtrain,\n",
    "                            valid_sets=[dtrain, dval],\n",
    "                            valid_names=['train', 'test'],\n",
    "                            categorical_feature=cat_feats,\n",
    "                            callbacks=[lgb.early_stopping(100, verbose=-1)],\n",
    "                            verbose_eval=False\n",
    "                            )\n",
    "            feat_importances_gain.append(model.feature_importance(importance_type='gain'))\n",
    "            feat_importances_split.append(model.feature_importance(importance_type='split'))\n",
    "        \n",
    "        gc.enable(); del data, X, y; gc.collect()\n",
    "        feat_importances_gain=np.array(feat_importances_gain).mean(axis=0)\n",
    "        feat_importances_split=np.array(feat_importances_split).mean(axis=0)\n",
    "        feat_importances_df=pd.DataFrame({'feature': cols,\n",
    "                                        'importance (gain)': feat_importances_gain,\n",
    "                                        'importance (split)': feat_importances_split,})\n",
    "        with open(feat_imp_path, 'wb') as f:\n",
    "            pickle.dump(feat_importances_df, f)\n",
    "    \n",
    "    elif mode=='test':\n",
    "        with open(feat_imp_path, 'rb') as f:\n",
    "            feat_importances_df=pickle.load(f)\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Specify mode (train of test) and path\")\n",
    "    return feat_importances_df\n",
    "\n",
    "\n",
    "\n",
    "def drop_zero_imp(df, feat_imp_path, k=5, params=None, mode='train', drop_by='importance (gain)'):\n",
    "    feature_imp_df=feat_imp_cv(df, feat_imp_path, k, params, mode=mode)\n",
    "    to_drop=feature_imp_df[feature_imp_df[drop_by]==0]['feature'].values\n",
    "    print(f'Num of features with zero importance: {len(to_drop)}')\n",
    "    return df.drop(to_drop, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def save_data(df, df_path, dtypes_path=None):\n",
    "    df.to_csv(df_path, index=False)\n",
    "    if dtypes_path:\n",
    "        with open(dtypes_path, 'wb') as f:\n",
    "            pickle.dump(df.dtypes, f)\n",
    "    print(f'Size: {round(sys.getsizeof(df) / 1e9, 2)}gb\\nShape: {df.shape}\\nSaved to: {df_path}')\n",
    "\n",
    "\n",
    "\n",
    "def train_model(df, params, model_path, col_tran_path):\n",
    "    X, y=df.drop(['SK_ID_CURR', 'TARGET'], axis=1), df['TARGET']\n",
    "    cat_cols, num_cols=X.select_dtypes(include=['object']).columns, X.select_dtypes('number').columns\n",
    "    ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    col_tran=ColumnTransformer([\n",
    "        ('cat', ohe, cat_cols),\n",
    "        ('num', 'passthrough', num_cols)\n",
    "    ])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=52, stratify=y)\n",
    "    X_train=col_tran.fit_transform(X_train)\n",
    "    X_val=col_tran.transform(X_val)\n",
    "    with open(col_tran_path, 'wb') as f:\n",
    "            pickle.dump(col_tran, f)\n",
    "    dtrain=lgb.Dataset(X_train, label=y_train, params={'verbose': -1})\n",
    "    dval=lgb.Dataset(X_val, label=y_val, params={'verbose': -1})\n",
    "    weight=np.count_nonzero(y==0)/np.count_nonzero(y==1)\n",
    "    params['scale_pos_weight']=weight\n",
    "    model=lgb.train(\n",
    "                    params=params,\n",
    "                    train_set=dtrain,\n",
    "                    valid_sets=[dtrain, dval],\n",
    "                    valid_names=['train', 'test'],\n",
    "                    callbacks=[lgb.early_stopping(100, verbose=-1)],\n",
    "                    verbose_eval=False\n",
    "                    )\n",
    "    model.save_model(model_path)\n",
    "    \n",
    "    return f'Model is saved in {model_path}'\n",
    "\n",
    "\n",
    "\n",
    "def make_prediction(X, model_path, col_tran_path, save_path=None):\n",
    "    with open(col_tran_path, 'rb') as f:\n",
    "        col_tran=pickle.load(f)\n",
    "    model=lgb.Booster(model_file=model_path)\n",
    "    pred=model.predict(col_tran.transform(X.drop('SK_ID_CURR', axis=1)))\n",
    "    if save_path:\n",
    "        submit=X[['SK_ID_CURR']]\n",
    "        submit.loc[:, 'TARGET']=pred\n",
    "        submit.to_csv(save_path, index=False)\n",
    "        return submit\n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "def timer():\n",
    "    print(f'Current time: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "\n",
    "\n",
    "\n",
    "def read_sample(data, nrows=None):\n",
    "    s=data.to_json(orient='records')\n",
    "    s=json.loads(s)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def predict_api(data, dtypes_path, model_path, ohe_path):\n",
    "    with open(ohe_path, 'rb') as f:\n",
    "        ohe=pickle.load(f)\n",
    "    model=lgb.Booster(model_file=model_path)\n",
    "    df=pd.DataFrame([data])\n",
    "    pred=model.predict(ohe.transform(df.drop('SK_ID_CURR', axis=1)))\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e34e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DICT={\n",
    "    'application_train': '../data/application_train.csv',\n",
    "    'application_test': '../data/application_test.csv',\n",
    "    'bur': '../data/bureau.csv',\n",
    "    'bb': '../data/bureau_balance.csv',\n",
    "    'previous': '../data/previous_application.csv',\n",
    "    'cash': '../data/POS_CASH_balance.csv',\n",
    "    'installments': '../data/installments_payments.csv',\n",
    "    'card_balance': '../data/credit_card_balance.csv',\n",
    "    'ohe_dict': '../models/pipeline/ohe_dict.pkl',\n",
    "    'corr_matrix': '../data/corr_matrix.csv',\n",
    "    'missing_columns_drop': '../models/pipeline/missing_columns_drop.pkl',\n",
    "    'zero_variance_drop': '../models/pipeline/zero_var_columns_drop.pkl',\n",
    "    'zero_imp_drop': '../models/pipeline/zero_imp.pkl',\n",
    "    'model_file': '../models/model.txt',\n",
    "    'lgb_ohe': '../models/pipeline/lgb_ohe.pkl',\n",
    "    'train_ready_file': '../data/train_ready.csv',\n",
    "    'test_ready_file': '../data/test_ready.csv',\n",
    "    'dtypes': '../models/pipeline/dtypes.pkl',\n",
    "    'submit': '../data/submit.csv',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f78889f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application data shape: (307511, 122)\n",
      "After adding features: (307511, 166)\n",
      "Bureau shape: (1716428, 17)\n",
      "Bureau balance shape: (27299925, 3)\n",
      "Dataset:bureau_balance\n",
      "\tBefore: 2 numeric cols\n",
      "\tAfter: 5\n",
      "Dataset:bureau_balance\n",
      "\tBefore: 1 categorical cols\n",
      "\tAfter: 16\n",
      "Dataset:loan\n",
      "\tBefore: 22 numeric cols\n",
      "\tAfter: 85\n",
      "Dataset:bureau\n",
      "\tBefore: 3 categorical cols\n",
      "\tAfter: 46\n",
      "Dataset:bureau\n",
      "\tBefore: 13 numeric cols\n",
      "\tAfter: 56\n",
      "Previous shape: (1670214, 37)\n",
      "Dataset:previous\n",
      "\tBefore: 16 categorical cols\n",
      "\tAfter: 286\n",
      "Dataset:previous\n",
      "\tBefore: 19 numeric cols\n",
      "\tAfter: 85\n",
      "Cash shape: (10001358, 8)\n",
      "Dataset:cash\n",
      "\tBefore: 1 categorical cols\n",
      "\tAfter: 18\n",
      "Dataset:cash\n",
      "\tBefore: 6 numeric cols\n",
      "\tAfter: 23\n",
      "Dataset:loan\n",
      "\tBefore: 42 numeric cols\n",
      "\tAfter: 162\n",
      "Installments shape: (13605401, 8)\n",
      "Dataset:inst\n",
      "\tBefore: 7 numeric cols\n",
      "\tAfter: 26\n",
      "Dataset:loan\n",
      "\tBefore: 27 numeric cols\n",
      "\tAfter: 106\n",
      "Card Balance shape: (3840312, 23)\n",
      "Dataset:card\n",
      "\tBefore: 1 categorical cols\n",
      "\tAfter: 14\n",
      "Dataset:card\n",
      "\tBefore: 21 numeric cols\n",
      "\tAfter: 83\n",
      "Dataset:loan\n",
      "\tBefore: 98 numeric cols\n",
      "\tAfter: 376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(307511, 1368)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train=full_df(PATH_DICT, mode='train')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21143824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application data shape: (48744, 121)\n",
      "After adding features: (48744, 165)\n",
      "Bureau shape: (1716428, 17)\n",
      "Bureau balance shape: (27299925, 3)\n",
      "Dataset:bureau_balance\n",
      "\tBefore: 2 numeric cols\n",
      "\tAfter: 5\n",
      "Dataset:bureau_balance\n",
      "\tBefore: 1 categorical cols\n",
      "\tAfter: 16\n",
      "Dataset:loan\n",
      "\tBefore: 22 numeric cols\n",
      "\tAfter: 85\n",
      "Dataset:bureau\n",
      "\tBefore: 3 categorical cols\n",
      "\tAfter: 46\n",
      "Dataset:bureau\n",
      "\tBefore: 13 numeric cols\n",
      "\tAfter: 56\n",
      "Previous shape: (1670214, 37)\n",
      "Dataset:previous\n",
      "\tBefore: 16 categorical cols\n",
      "\tAfter: 286\n",
      "Dataset:previous\n",
      "\tBefore: 19 numeric cols\n",
      "\tAfter: 85\n",
      "Cash shape: (10001358, 8)\n",
      "Dataset:cash\n",
      "\tBefore: 1 categorical cols\n",
      "\tAfter: 18\n",
      "Dataset:cash\n",
      "\tBefore: 6 numeric cols\n",
      "\tAfter: 23\n",
      "Dataset:loan\n",
      "\tBefore: 42 numeric cols\n",
      "\tAfter: 162\n",
      "Installments shape: (13605401, 8)\n",
      "Dataset:inst\n",
      "\tBefore: 7 numeric cols\n",
      "\tAfter: 26\n",
      "Dataset:loan\n",
      "\tBefore: 27 numeric cols\n",
      "\tAfter: 106\n",
      "Card Balance shape: (3840312, 23)\n",
      "Dataset:card\n",
      "\tBefore: 1 categorical cols\n",
      "\tAfter: 14\n",
      "Dataset:card\n",
      "\tBefore: 21 numeric cols\n",
      "\tAfter: 83\n",
      "Dataset:loan\n",
      "\tBefore: 98 numeric cols\n",
      "\tAfter: 376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48744, 1367)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=full_df(PATH_DICT, mode='test')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f24af8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TARGET'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns)-set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7563fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quick_cv(df):\n",
    "#     X, y=df.drop(['SK_ID_CURR', 'TARGET'], axis=1), df['TARGET']\n",
    "#     cat_cols, num_cols=X.select_dtypes(include=['category', 'object']).columns, X.select_dtypes('number').columns\n",
    "\n",
    "#     ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "#     col_tr=ColumnTransformer([\n",
    "#         ('cat', ohe, cat_cols),\n",
    "#         ('num', 'passthrough', num_cols)\n",
    "#     ])\n",
    "\n",
    "#     res, importances=custom_lgbm_cv(X, y, col_tr)\n",
    "#     return res, importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f90f7c",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db983a",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53ed598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_filter(df, thresh, corr_path, mode='train'):\n",
    "    if mode=='train':\n",
    "        corr_mat=df.drop(['SK_ID_CURR', 'TARGET'], axis=1).corr().abs()\n",
    "        upper=corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(np.bool))\n",
    "        upper.to_csv(corr_path, index=False)\n",
    "    elif mode=='test':\n",
    "        upper=pd.read_csv(corr_path)\n",
    "    to_drop=[column for column in upper.columns if any(upper[column]>thresh)]\n",
    "    print(f'Correlation: {len(to_drop)} will be removed')\n",
    "    return df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae749e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 619 will be removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(307511, 749)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=correlation_filter(train, 0.9, '../data/corr_matrix.csv', \n",
    "                         mode='test',\n",
    "#                         mode='train',\n",
    "                        )\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea72606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 619 will be removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48744, 748)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=correlation_filter(test, 0.9, '../data/corr_matrix.csv', mode='test')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec93d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TARGET'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns)-set(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55260cfa",
   "metadata": {},
   "source": [
    "## Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1ac8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_filter(df, thresh, col_path, mode='train'):\n",
    "    if mode=='train':\n",
    "        mt=miss_table(df)\n",
    "        to_drop=mt.loc[mt['Percent']>thresh].index\n",
    "        with open(col_path, 'wb') as f:\n",
    "            pickle.dump(to_drop, f)\n",
    "    elif mode=='test':\n",
    "        with open(col_path, 'rb') as f:\n",
    "            to_drop=pickle.load(f)\n",
    "    else:\n",
    "        raise Exception(\"Specify mode (train of test) and path\")\n",
    "    print(f'{len(to_drop)} features with {thresh}% of NaNs will be removed')\n",
    "    return df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee8f7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 689/749 columns with missing values\n",
      "Distribution by dtypes:\n",
      "float32    683\n",
      "object       6\n",
      "Name: Dtype, dtype: int64\n",
      "16 features with 80% of NaNs will be removed\n"
     ]
    }
   ],
   "source": [
    "train=missing_filter(train, 80, '../models/pipeline/missing_columns_drop.pkl', 'train',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d32315f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 features with 80% of NaNs will be removed\n"
     ]
    }
   ],
   "source": [
    "test=missing_filter(test, 80, '../models/pipeline/missing_columns_drop.pkl', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe64680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TARGET'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns)-set(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29efce",
   "metadata": {},
   "source": [
    "## Zero Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d068116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_var_filter(df, col_path, mode='train'):\n",
    "    if mode=='train':\n",
    "        scaler=MinMaxScaler()\n",
    "        numeric_data=df.drop('SK_ID_CURR', axis=1).select_dtypes('number').reset_index(drop=True)\n",
    "        numeric_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        for i in numeric_data.columns:\n",
    "            numeric_data[i].fillna(value=numeric_data[i].mean(), inplace=True) #replace NaN with mean of dimension\n",
    "            numeric_data[i]=scaler.fit_transform(numeric_data[i].values.reshape(-1,1)) \n",
    "        vars_df=numeric_data.var()\n",
    "        to_drop=vars_df[vars_df==0].index\n",
    "        with open(col_path, 'wb') as f:\n",
    "            pickle.dump(to_drop, f)\n",
    "    \n",
    "    elif mode=='test':\n",
    "        with open(col_path, 'rb') as f:\n",
    "            to_drop=pickle.load(f)\n",
    "    else:\n",
    "        raise Exception(\"Specify mode (train of test) and path\")\n",
    "    print(f'{len(to_drop)} features with zero variance will be removed')\n",
    "    return df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06ce766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 features with zero variance will be removed\n"
     ]
    }
   ],
   "source": [
    "train=zero_var_filter(train, '../models/pipeline/zero_var_columns_drop.pkl', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c44b0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 features with zero variance will be removed\n"
     ]
    }
   ],
   "source": [
    "test=zero_var_filter(test, '../models/pipeline/zero_var_columns_drop.pkl', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6302e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TARGET'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns)-set(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a89184",
   "metadata": {},
   "source": [
    "## Zero Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73aba613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_imp_cv(df, feat_imp_path, k=5, params=None, mode='train'):\n",
    "    if mode=='train':\n",
    "        for c in df:\n",
    "            if (df[c].dtype=='object') and (df[c].nunique()<df.shape[0]):\n",
    "                df[c]=df[c].astype('category')\n",
    "        X, y=df.drop(['SK_ID_CURR', 'TARGET'], axis=1), df['TARGET']\n",
    "        feat_importances_gain, feat_importances_split=[], []\n",
    "        kfold=StratifiedKFold(k)\n",
    "        for f, (tr, te) in enumerate(kfold.split(X, y=y)):\n",
    "            X_train, y_train=X.iloc[tr, :], y.iloc[tr]\n",
    "            X_test, y_test=X.iloc[te, :], y.iloc[te]\n",
    "            weight=np.count_nonzero(y_train==0)/np.count_nonzero(y_train==1)\n",
    "            params['scale_pos_weight']=weight\n",
    "            dtrain=lgb.Dataset(X_train, label=y_train, params={'verbose': -1})\n",
    "            dval=lgb.Dataset(X_test, label=y_test, params={'verbose': -1})\n",
    "            model=lgb.train(\n",
    "                            params=params,\n",
    "                            train_set=dtrain,\n",
    "                            valid_sets=[dtrain, dval],\n",
    "                            valid_names=['train', 'test'],\n",
    "                            categorical_feature=list(X.select_dtypes(['category']).columns),\n",
    "                            callbacks=[lgb.early_stopping(100, verbose=-1)],\n",
    "                            verbose_eval=False\n",
    "                            )\n",
    "            feat_importances_gain.append(model.feature_importance(importance_type='gain'))\n",
    "            feat_importances_split.append(model.feature_importance(importance_type='split'))\n",
    "            \n",
    "        feat_importances_gain=np.array(feat_importances_gain).mean(axis=0)\n",
    "        feat_importances_split=np.array(feat_importances_split).mean(axis=0)\n",
    "        feat_importances_df=pd.DataFrame({'feature': list(X.columns),\n",
    "                                        'importance (gain)': feat_importances_gain,\n",
    "                                        'importance (split)': feat_importances_split,})\n",
    "        with open(feat_imp_path, 'wb') as f:\n",
    "            pickle.dump(feat_importances_df, f)\n",
    "    \n",
    "    elif mode=='test':\n",
    "        with open(feat_imp_path, 'rb') as f:\n",
    "            feat_importances_df=pickle.load(f)\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Specify mode (train of test) and path\")\n",
    "    return feat_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7523243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_zero_imp(df, feat_imp_path, k=5, params=None, mode='train', drop_by='importance (gain)'):\n",
    "    feature_imp_df=feat_imp_cv(df, feat_imp_path, k, params, mode=mode)\n",
    "    to_drop=feature_imp_df[feature_imp_df[drop_by]==0]['feature'].values\n",
    "    print(f'Num of features with zero importance: {len(to_drop)}')\n",
    "    return df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79df5f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[383]\ttrain's auc: 0.87577\ttest's auc: 0.783501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttrain's auc: 0.879807\ttest's auc: 0.787868\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[316]\ttrain's auc: 0.865129\ttest's auc: 0.780138\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\ttrain's auc: 0.851291\ttest's auc: 0.785895\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[427]\ttrain's auc: 0.881463\ttest's auc: 0.782358\n",
      "Num of features with zero importance: 172\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "train=train.rename(columns=lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "test=test.rename(columns=lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "params={'num_boost_round': 10000,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 5,\n",
    "       'verbose': -1}\n",
    "\n",
    "train=drop_zero_imp(train, '../models/pipeline/zero_imp.pkl', 5, params, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e6d12bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of features with zero importance: 172\n"
     ]
    }
   ],
   "source": [
    "test=drop_zero_imp(test, '../models/pipeline/zero_imp.pkl', 5, params, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca781f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TARGET'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns)-set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19da27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../data/train_ready.csv', index=False)\n",
    "test.to_csv('../data/test_ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f10ba9",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e7e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=convert_types(pd.read_csv('../data/train_ready.csv'))\n",
    "test= convert_types(pd.read_csv('../data/test_ready.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9447e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, params, model_path, col_tran_path):\n",
    "    X, y=df.drop(['SK_ID_CURR', 'TARGET'], axis=1), df['TARGET']\n",
    "    cat_cols, num_cols=X.select_dtypes(include=['category', 'object']).columns, X.select_dtypes('number').columns\n",
    "    ohe=OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    col_tran=ColumnTransformer([\n",
    "        ('cat', ohe, cat_cols),\n",
    "        ('num', 'passthrough', num_cols)\n",
    "    ])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=52, stratify=y)\n",
    "    X_train=col_tran.fit_transform(X_train)\n",
    "    X_val=col_tran.transform(X_val)\n",
    "    with open(col_tran_path, 'wb') as f:\n",
    "            pickle.dump(col_tran, f)\n",
    "    dtrain=lgb.Dataset(X_train, label=y_train, params={'verbose': -1})\n",
    "    dval=lgb.Dataset(X_val, label=y_val, params={'verbose': -1})\n",
    "    weight=np.count_nonzero(y==0)/np.count_nonzero(y==1)\n",
    "    params['scale_pos_weight']=weight\n",
    "    model=lgb.train(\n",
    "                    params=params,\n",
    "                    train_set=dtrain,\n",
    "                    valid_sets=[dtrain, dval],\n",
    "                    valid_names=['train', 'test'],\n",
    "                    callbacks=[lgb.early_stopping(100, verbose=-1)],\n",
    "                    verbose_eval=False\n",
    "                    )\n",
    "    model.save_model(model_path)\n",
    "    \n",
    "    return f'Model is saved in {model_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d23d5717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttrain's auc: 0.883505\ttest's auc: 0.790682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model is saved in ../models/model.txt'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMS={\n",
    "    'num_boost_round': 10000,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 5,\n",
    "    'verbose': -1\n",
    "    }\n",
    "\n",
    "train_model(train, PARAMS, PATH_DICT['model_file'], PATH_DICT['lgb_ohe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b056e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(X, model_path, col_tran_path, save_path=None):\n",
    "    with open(col_tran_path, 'rb') as f:\n",
    "        col_tran=pickle.load(f)\n",
    "    model=lgb.Booster(model_file=model_path)\n",
    "    pred=model.predict(col_tran.transform(X.drop('SK_ID_CURR', axis=1)))\n",
    "    if save_path:\n",
    "        submit=X[['SK_ID_CURR']]\n",
    "        submit.loc[:, 'TARGET']=pred\n",
    "        submit.to_csv(save_path, index=False)\n",
    "        return submit\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "afb6aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akim.Alikhanov\\AppData\\Local\\Temp\\ipykernel_12580\\1287600273.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit.loc[:, 'TARGET']=pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.1752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SK_ID_CURR  TARGET\n",
       "0     100001  0.1752"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(test.loc[0].to_frame().T, PATH_DICT['model_file'], PATH_DICT['lgb_ohe'], save_path=PATH_DICT['submit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1fcbfcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akim.Alikhanov\\AppData\\Local\\Temp\\ipykernel_12580\\1287600273.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit.loc[:, 'TARGET']=pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.6038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.7083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>456221</td>\n",
       "      <td>0.3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>456222</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>456223</td>\n",
       "      <td>0.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>456224</td>\n",
       "      <td>0.1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>456250</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR  TARGET\n",
       "0          100001  0.1752\n",
       "1          100005  0.6038\n",
       "2          100013  0.1104\n",
       "3          100028  0.1582\n",
       "4          100038  0.7083\n",
       "...           ...     ...\n",
       "48739      456221  0.3215\n",
       "48740      456222  0.4215\n",
       "48741      456223  0.0784\n",
       "48742      456224  0.1979\n",
       "48743      456250  0.7193\n",
       "\n",
       "[48744 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(test, PATH_DICT['model_file'], PATH_DICT['lgb_ohe'], save_path=PATH_DICT['submit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86d72888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test=train_test_split(train, test_size=0.15, random_state=52, stratify=train['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ed70c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akim.Alikhanov\\AppData\\Local\\Temp\\ipykernel_16584\\1863600980.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submit.loc[:, 'TARGET']=model.predict(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.2547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.5834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.2430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.6866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>456221</td>\n",
       "      <td>0.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>456222</td>\n",
       "      <td>0.3706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>456223</td>\n",
       "      <td>0.0716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>456224</td>\n",
       "      <td>0.3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>456250</td>\n",
       "      <td>0.6848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR  TARGET\n",
       "0          100001  0.2547\n",
       "1          100005  0.5834\n",
       "2          100013  0.2775\n",
       "3          100028  0.2430\n",
       "4          100038  0.6866\n",
       "...           ...     ...\n",
       "48739      456221  0.3735\n",
       "48740      456222  0.3706\n",
       "48741      456223  0.0716\n",
       "48742      456224  0.3177\n",
       "48743      456250  0.6848\n",
       "\n",
       "[48744 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=make_prediction(test, '../models/model.txt', '../data/submit.csv')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f9ebcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_true, y_pred):    \n",
    "    # Creating a confusion matrix\n",
    "    con_mat = confusion_matrix(y_true, y_pred)\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                con_mat.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                         con_mat.flatten()/np.sum(con_mat)]\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in\n",
    "              zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    #Ploting the confusion matrix\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    sns.set(font_scale=1.5) \n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    s=sns.heatmap(con_mat, annot=labels, annot_kws={\"size\": 16}, fmt='', cmap='Blues', cbar=False)\n",
    "    s.set(ylabel='True', xlabel='Pred')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92296ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix(y_test, np.where(pred>=0.60, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6e869f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2273"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gc.enable()\n",
    "# del train, test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41eae350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,1,4,4])\n",
    "np.std(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0463811",
   "metadata": {},
   "source": [
    "## Get Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d6d3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app: (1, 121)\n",
      "bur: (3, 17)\n",
      "bb: (21, 3)\n",
      "prev: (2, 37)\n",
      "inst: (9, 8)\n",
      "cash: (11, 8)\n",
      "card: (0, 23)\n"
     ]
    }
   ],
   "source": [
    "def create_sample(client_id, path_dict, save_dict):\n",
    "    app=pd.read_csv(path_dict['application_test'])\n",
    "    client_app=app.loc[app['SK_ID_CURR']==client_id, :].astype(app.dtypes)\n",
    "    client_app.to_csv(save_dict['application_test'], index=False)\n",
    "    print(f'app: {client_app.shape}')\n",
    "    gc.enable(); del app, client_app; gc.collect()\n",
    "\n",
    "    bur=pd.read_csv(path_dict['bur'])\n",
    "    client_bur=bur.loc[bur['SK_ID_CURR']==client_id, :].astype(bur.dtypes)\n",
    "    client_bur.to_csv(save_dict['bur'], index=False)\n",
    "    print(f'bur: {client_bur.shape}')\n",
    "    del bur; gc.collect()\n",
    "\n",
    "    bb=pd.read_csv(path_dict['bb'])\n",
    "    client_bb=bb.loc[bb['SK_ID_BUREAU'].isin(client_bur['SK_ID_BUREAU']), :].astype(bb.dtypes)\n",
    "    client_bb.to_csv(save_dict['bb'], index=False)\n",
    "    print(f'bb: {client_bb.shape}')\n",
    "    del bb, client_bb, client_bur; gc.collect()\n",
    "\n",
    "    prev=pd.read_csv(path_dict['previous'])\n",
    "    client_prev=prev.loc[prev['SK_ID_CURR']==client_id, :].astype(prev.dtypes)\n",
    "    client_prev.to_csv(save_dict['previous'], index=False)\n",
    "    print(f'prev: {client_prev.shape}')\n",
    "    del prev, client_prev; gc.collect()\n",
    "    \n",
    "    inst=pd.read_csv(config.PATH_DICT['installments'])\n",
    "    client_inst=inst.loc[inst['SK_ID_CURR']==client_id, :].astype(inst.dtypes)\n",
    "    client_inst.to_csv(save_dict['installments'], index=False)\n",
    "    print(f'inst: {client_inst.shape}')\n",
    "    del inst, client_inst; gc.collect()\n",
    "\n",
    "    cash=pd.read_csv(config.PATH_DICT['cash'])\n",
    "    client_cash=cash.loc[cash['SK_ID_CURR']==client_id, :].astype(cash.dtypes)\n",
    "    client_cash.to_csv(save_dict['cash'], index=False)\n",
    "    print(f'cash: {client_cash.shape}')\n",
    "    del cash, client_cash; gc.collect()\n",
    "\n",
    "    card=pd.read_csv(config.PATH_DICT['card_balance'])\n",
    "    client_card=card.loc[card['SK_ID_CURR']==client_id, :].astype(card.dtypes)\n",
    "    client_card.to_csv(save_dict['card_balance'], index=False)\n",
    "    print(f'card: {client_card.shape}')\n",
    "    del card, client_card; gc.collect()\n",
    "\n",
    "create_sample(100005, config.PATH_DICT, config.SAMPLES_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a65c7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_PREV', 'SK_ID_CURR', 'MONTHS_BALANCE', 'CNT_INSTALMENT',\n",
       "       'CNT_INSTALMENT_FUTURE', 'NAME_CONTRACT_STATUS', 'SK_DPD',\n",
       "       'SK_DPD_DEF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/samples/cash_sample.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d2eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a998bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_train\n",
      "bur\n",
      "bb\n",
      "previous\n",
      "cash\n",
      "installments\n",
      "card_balance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All datatypes saved to ../models/pipeline/sample_dtypes_dict.pkl'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_dtypes(df_names, path_dict, sample_dtypes_path):\n",
    "    sample_dtypes_dict={}\n",
    "    for i in df_names:\n",
    "        print(i)\n",
    "        df=pd.read_csv(path_dict[i])\n",
    "        sample_dtypes_dict[i]=df.dtypes\n",
    "    with open(sample_dtypes_path, 'wb') as f:\n",
    "        pickle.dump(sample_dtypes_dict, f)\n",
    "    return f'All datatypes saved to {sample_dtypes_path}'\n",
    "  \n",
    "names=['application_train','bur','bb','previous','cash','installments','card_balance']\n",
    "save_dtypes(names, config.PATH_DICT, '../models/pipeline/sample_dtypes_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5862d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_sample(client_id, samples_dict, path_dict, sample_dtypes_path):\n",
    "    with open(path_dict['ohe_dict'], 'rb') as f:\n",
    "        ohe_dict=pickle.load(f)\n",
    "        \n",
    "    with open(sample_dtypes_path, 'rb') as f:\n",
    "        orig_dtypes_dict=pickle.load(f)\n",
    "        \n",
    "    app=application_data(samples_dict['application_test']).astype(orig_dtypes_dict['application_train'].drop('TARGET'))\n",
    "    client_id=app['SK_ID_CURR'].values[0]\n",
    "    try:\n",
    "        bur, bb, _, _=bureau_and_bb(samples_dict['bur'], \n",
    "                                    samples_dict['bb'], \n",
    "                                    bur_ohe=ohe_dict['Bureau_OHE'], \n",
    "                                    bb_ohe=ohe_dict['BB_OHE'],\n",
    "                                    remove_dup=False, sample=[orig_dtypes_dict['bur'], orig_dtypes_dict['bb']])\n",
    "        bur.rename(columns=lambda s: s.replace(\" \", \"\"), inplace=True)\n",
    "        bb.rename(columns=lambda s: s.replace(\" \", \"\"), inplace=True)\n",
    "        app=app.merge(bur, on='SK_ID_CURR', how='left')\n",
    "        del bur; gc.collect()\n",
    "        app=app.merge(bb, on='SK_ID_CURR', how='left')\n",
    "        del bb; gc.collect()\n",
    "    except ValueError as e:\n",
    "        print(f'{e}')\n",
    "       \n",
    "    \n",
    "    try:\n",
    "        prev, _=previous(samples_dict['previous'], prev_ohe=ohe_dict['Prev_OHE'], remove_dup=False, sample=orig_dtypes_dict['previous'])\n",
    "    except ValueError as e:\n",
    "        with open(path_dict['prev_temp'], 'rb') as f:\n",
    "            prev=pickle.load(f)\n",
    "        prev['SK_ID_CURR']=client_id\n",
    "    for i in [' ', '-', ':', ')', '(', '+', '/', ',']:\n",
    "        prev.rename(columns=lambda s: s.replace(i, \"\"), inplace=True)\n",
    "    app=app.merge(prev, on='SK_ID_CURR', how='left')\n",
    "    del prev; gc.collect()\n",
    "      \n",
    "    \n",
    "    try:\n",
    "        cash, _=pos_cash(samples_dict['cash'], cash_ohe=ohe_dict['Cash_OHE'], remove_dup=False, sample=orig_dtypes_dict['cash'])\n",
    "    except ValueError as e:\n",
    "        with open(path_dict['cash_temp'], 'rb') as f:\n",
    "            cash=pickle.load(f)\n",
    "        cash['SK_ID_CURR']=client_id\n",
    "    cash.rename(columns=lambda s: s.replace(\" \", \"\"), inplace=True)\n",
    "    app=app.merge(cash, on='SK_ID_CURR', how='left')\n",
    "    del cash; gc.collect()\n",
    "      \n",
    "    \n",
    "    try:\n",
    "        inst=installments(samples_dict['installments'], remove_dup=False, sample=orig_dtypes_dict['installments'])\n",
    "    except ValueError as e:\n",
    "        with open(path_dict['inst_temp'], 'rb') as f:\n",
    "            inst=pickle.load(f)\n",
    "        inst['SK_ID_CURR']=client_id\n",
    "    inst.rename(columns=lambda s: s.replace(\" \", \"\"), inplace=True)\n",
    "    app=app.merge(inst, on='SK_ID_CURR', how='left')\n",
    "    del inst; gc.collect()\n",
    "    \n",
    "    \n",
    "    try:    \n",
    "        card_b, _=card_balance(samples_dict['card_balance'], card_ohe=ohe_dict['Card_OHE'], \n",
    "                              remove_dup=False, sample=orig_dtypes_dict['card_balance'])\n",
    "    except ValueError as e:\n",
    "        with open(path_dict['card_temp'], 'rb') as f:\n",
    "            card_b=pickle.load(f)\n",
    "        card_b['SK_ID_CURR']=client_id\n",
    "        \n",
    "    card_b.rename(columns=lambda s: s.replace(\" \", \"\"), inplace=True)\n",
    "    app=app.merge(card_b, on='SK_ID_CURR', how='left')\n",
    "    del card_b; gc.collect()\n",
    "    \n",
    "    with open(path_dict['dtypes'], 'rb') as f:\n",
    "        final_dtypes=pickle.load(f)\n",
    "        \n",
    "    return app[final_dtypes.drop('TARGET').index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b08ca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'application_test': '../data/clients/100001/application.csv',\n",
       " 'bur': '../data/clients/100001/bureau.csv',\n",
       " 'bb': '../data/clients/100001/bureau_balance.csv',\n",
       " 'previous': '../data/clients/100001/previous_app.csv',\n",
       " 'cash': '../data/clients/100001/cash.csv',\n",
       " 'installments': '../data/clients/100001/installments.csv',\n",
       " 'card_balance': '../data/clients/100001/card.csv'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa=dict(zip(config.SAMPLES_DICT.keys(), [f'../data/clients/{100001}/'+dir_ for dir_ in config.CLIENT_FILENAMES]))\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d42c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application data shape: (1, 121)\n",
      "After adding features: (1, 165)\n",
      "Bureau shape: (7, 17)\n",
      "Bureau balance shape: (172, 3)\n",
      "Dataset:bureau_balance\n",
      "\tBefore: 2 numeric cols\n",
      "\tAfter: 5\n",
      "Dataset:bureau_balance\n",
      "\tBefore: 1 categorical cols\n",
      "\tAfter: 16\n",
      "Dataset:loan\n",
      "\tBefore: 22 numeric cols\n",
      "\tAfter: 105\n",
      "Dataset:bureau\n",
      "\tBefore: 3 categorical cols\n",
      "\tAfter: 46\n",
      "Dataset:bureau\n",
      "\tBefore: 13 numeric cols\n",
      "\tAfter: 60\n",
      "Previous shape: (1, 37)\n",
      "Dataset:previous\n",
      "\tBefore: 16 categorical cols\n",
      "\tAfter: 290\n",
      "Dataset:previous\n",
      "\tBefore: 20 numeric cols\n",
      "\tAfter: 95\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Only a column name can be used for the key in a dtype mappings argument. 'MONTHS_BALANCE' not found in columns.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m a\u001b[38;5;241m=\u001b[39m\u001b[43mfull_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maaa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPATH_DICT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/pipeline/sample_dtypes_dict.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m a\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[1;32mIn [2], line 39\u001b[0m, in \u001b[0;36mfull_sample\u001b[1;34m(client_id, samples_dict, path_dict, sample_dtypes_path)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m prev; gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     cash, _\u001b[38;5;241m=\u001b[39m\u001b[43mpos_cash\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcash_ohe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mohe_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCash_OHE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_dup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_dtypes_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcash_temp\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32m~\\Desktop\\kaggle\\home_credit_scoring\\notebooks\\../src\\utils.py:300\u001b[0m, in \u001b[0;36mpos_cash\u001b[1;34m(cash_path, enc_mode, cash_ohe, remove_dup, sample, template_path)\u001b[0m\n\u001b[0;32m    298\u001b[0m cash\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(cash_path)\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m     cash\u001b[38;5;241m=\u001b[39m\u001b[43mcash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m cash\u001b[38;5;241m=\u001b[39mconvert_types(pd\u001b[38;5;241m.\u001b[39mread_csv(cash_path))\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCash shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcash\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5879\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5877\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   5878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m-> 5879\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m   5880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly a column name can be used for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5881\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey in a dtype mappings argument. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5882\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5883\u001b[0m         )\n\u001b[0;32m   5885\u001b[0m \u001b[38;5;66;03m# GH#44417 cast to Series so we can use .iat below, which will be\u001b[39;00m\n\u001b[0;32m   5886\u001b[0m \u001b[38;5;66;03m#  robust in case we\u001b[39;00m\n\u001b[0;32m   5887\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Only a column name can be used for the key in a dtype mappings argument. 'MONTHS_BALANCE' not found in columns.\""
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "a=full_sample(100001, aaa, config.PATH_DICT, '../models/pipeline/sample_dtypes_dict.pkl')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2250bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57142201])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(a, config.PATH_DICT['model_file'], config.PATH_DICT['lgb_ohe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b1db1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/pipeline/sample_dtypes_dict.pkl', 'rb') as f:\n",
    "    orig_dtypes=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656ceb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'application_test': '../data/clients/100001/application.csv',\n",
       " 'bur': '../data/clients/100001/bureau.csv',\n",
       " 'bb': '../data/clients/100001/bureau_balance.csv',\n",
       " 'previous': '../data/clients/100001/previous_app.csv',\n",
       " 'cash': '../data/clients/100001/cash.csv',\n",
       " 'installments': '../data/clients/100001/installments.csv',\n",
       " 'card_balance': '../data/clients/100001/card.csv'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(config.SAMPLES_DICT.keys(), [f'../data/clients/{100001}/'+dir_ for dir_ in config.CLIENT_FILENAMES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2caa258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1851984</td>\n",
       "      <td>100001</td>\n",
       "      <td>-96</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851984</td>\n",
       "      <td>100001</td>\n",
       "      <td>-95</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Active</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1369693</td>\n",
       "      <td>100001</td>\n",
       "      <td>-53</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1369693</td>\n",
       "      <td>100001</td>\n",
       "      <td>-54</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1851984</td>\n",
       "      <td>100001</td>\n",
       "      <td>-93</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1369693</td>\n",
       "      <td>100001</td>\n",
       "      <td>-57</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1369693</td>\n",
       "      <td>100001</td>\n",
       "      <td>-55</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1851984</td>\n",
       "      <td>100001</td>\n",
       "      <td>-94</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1369693</td>\n",
       "      <td>100001</td>\n",
       "      <td>-56</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  CNT_INSTALMENT  \\\n",
       "0     1851984      100001             -96          4.0000   \n",
       "1     1851984      100001             -95          4.0000   \n",
       "2     1369693      100001             -53          4.0000   \n",
       "3     1369693      100001             -54          4.0000   \n",
       "4     1851984      100001             -93          4.0000   \n",
       "5     1369693      100001             -57          4.0000   \n",
       "6     1369693      100001             -55          4.0000   \n",
       "7     1851984      100001             -94          4.0000   \n",
       "8     1369693      100001             -56          4.0000   \n",
       "\n",
       "   CNT_INSTALMENT_FUTURE NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "0                 2.0000               Active       0           0  \n",
       "1                 1.0000               Active       7           7  \n",
       "2                 0.0000            Completed       0           0  \n",
       "3                 1.0000               Active       0           0  \n",
       "4                 0.0000            Completed       0           0  \n",
       "5                 4.0000               Active       0           0  \n",
       "6                 2.0000               Active       0           0  \n",
       "7                 0.0000               Active       0           0  \n",
       "8                 3.0000               Active       0           0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/clients/100001/cash.csv').astype(orig_dtypes['cash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85a83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
